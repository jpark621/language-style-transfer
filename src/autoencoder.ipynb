{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a mind to strike thee ere thou speak’st.\n",
      "Yet if thou say Antony lives, is well, Or friends wi\n",
      "I have half a mind to hit you before you speak again.\n",
      "But if Antony is alive, healthy, friendly with\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "import os\n",
    "\n",
    "original_dir_path = '../data/shakespeare/original/'\n",
    "modern_dir_path = '../data/shakespeare/modern/'\n",
    "\n",
    "def read_all_files(dir_path):\n",
    "    docs = \"\"\n",
    "    for filename in os.listdir(dir_path):\n",
    "        with open(dir_path + filename, 'r') as file:\n",
    "            docs += file.read()\n",
    "    return docs\n",
    "\n",
    "original_docs = read_all_files(original_dir_path)\n",
    "modern_docs = read_all_files(modern_dir_path)\n",
    "\n",
    "print(original_docs[:100])\n",
    "print(modern_docs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'a', 'mind', 'to', 'strike', 'thee', 'ere', 'thou', 'speak’st', 'Yet', 'if', 'thou', 'say', 'Antony', 'lives,', 'is', 'well,', 'Or', 'friends', 'with', 'Caesar,', 'or', 'not', 'captive', 'to', 'him,', 'I’ll', 'set', 'thee', 'in', 'a', 'shower', 'of', 'gold', 'and', 'hail', 'Rich', 'pearls', 'upon', 'thee', 'Madam,', 'he’s', 'well', 'Well', 'said', 'And', 'friends', 'with', 'Caesar', 'Th’', 'art', 'an', 'honest', 'man', 'Caesar', 'and', 'he', 'are', 'greater', 'friends', 'than', 'ever', 'Make', 'thee', 'a', 'fortune', 'from', 'me', 'But', 'yet,', 'madam—', 'I', 'do', 'not', 'like', '“But', 'yet”', 'It', 'does', 'allay', 'The', 'good', 'precedence', 'Fie', 'upon', '“But', 'yet”', '“But', 'yet”', 'is', 'as', 'a', 'jailer', 'to', 'bring', 'forth', 'Some', 'monstrous', 'malefactor']\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode entire dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset = (original_docs + \" \" + modern_docs).replace(\".\",\"\").replace(\"\\n\", \" \").split(\" \")\n",
    "print(dataset[:100])\n",
    "\n",
    "enc = LabelEncoder()\n",
    "enc.fit(dataset)\n",
    "V = len(enc.classes_) #size of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "original_sentences = original_docs.replace('.',\"\").split('\\n')\n",
    "modern_sentences = modern_docs.replace('.',\"\").split('\\n')\n",
    "\n",
    "original_sentences = original_sentences\n",
    "modern_sentences = modern_sentences\n",
    "\n",
    "max_length = 30\n",
    "\n",
    "X_org = []\n",
    "for sentence in original_sentences:\n",
    "    words = sentence.split(\" \")\n",
    "    try:\n",
    "        words = words[:30]\n",
    "    except:\n",
    "        pass\n",
    "    word_idx = np.array(enc.transform(words))\n",
    "    \n",
    "    arr = np.zeros(max_length)\n",
    "    arr[:len(words)] = word_idx\n",
    "    X_org.append(arr)\n",
    "    \n",
    "X_modern = []\n",
    "for sentence in modern_sentences:\n",
    "    words = sentence.split(\" \")\n",
    "    try:\n",
    "        words = words[:30]\n",
    "    except:\n",
    "        pass\n",
    "    word_idx = np.array(enc.transform(words))\n",
    "    \n",
    "    arr = np.zeros(max_length)\n",
    "    arr[:len(words)] = word_idx\n",
    "    X_modern.append(arr)\n",
    "\n",
    "X_org = np.array(X_org)\n",
    "X_mod = np.array(X_modern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "X_dict = {'X_org': X_org, 'X_mod': X_mod}\n",
    "pickle_path = '../models/X_shakespeare_ohe.pickle'\n",
    "\n",
    "with open(pickle_path, 'wb') as f:\n",
    "    pickle.dump(X_dict, f)\n",
    "\n",
    "X_dict_loaded = None\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    X_dict_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Overfit Autoencoder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def dense(x, n1, n2, name):\n",
    "    with tf.variable_scope(name, reuse=None):\n",
    "        weights = tf.get_variable(\"weights\", shape=[n1, n2], initializer=tf.random_normal_initializer(mean=0, stddev=0.01))\n",
    "        bias = tf.get_variable(\"bias\", shape=[n2], initializer=tf.constant_initializer(0.0))\n",
    "        out = tf.add(tf.matmul(x, weights), bias, name='matmul')\n",
    "        return out\n",
    "\n",
    "input_dim = max_length\n",
    "n_l1 = 100\n",
    "n_l2 = 100\n",
    "z_dim = 2\n",
    "\n",
    "def encoder(x, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.name_scope('Encoder'):\n",
    "        e_dense_1 = tf.nn.relu(dense(x, input_dim, n_l1, 'e_dense_1'))\n",
    "        e_dense_2 = tf.nn.relu(dense(e_dense_1, n_l1, n_l2, 'e_dense_2'))\n",
    "        latent_variable = dense(e_dense_2, n_l2, z_dim, 'e_latent_variable')\n",
    "        return latent_variable\n",
    "    \n",
    "def decoder(z, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_varaiable_scope().reuse_variables()\n",
    "    with tf.name_scope('Decodr'):\n",
    "        d_dense_1 = tf.nn.relu(dense(z, z_dim, n_l2, 'd_dense_1'))\n",
    "        d_dense_2 = tf.nn.relu(dense(d_dense_1, n_l2, n_l1, 'd_dense_2'))\n",
    "        output = dense(d_dense_2, n_l2, input_dim, 'd_output')\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "beta1 = 0.9\n",
    "\n",
    "x_input = tf.placeholder(tf.float32, [None, max_length])\n",
    "\n",
    "encoder_output = encoder(x_input)\n",
    "decoder_output = decoder(encoder_output)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(decoder_output - x_input))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 10412233.0\n",
      "Loss: 4148458.5\n",
      "Loss: 4148045.25\n",
      "Loss: 4146912.75\n",
      "Loss: 4145893.5\n",
      "Loss: 4147863.5\n",
      "Loss: 4146901.0\n",
      "Loss: 4146691.0\n",
      "Loss: 4146446.25\n",
      "Loss: 4146140.25\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "num_epochs = 10\n",
    "X = X_org\n",
    "batch_size = 100\n",
    "\n",
    "step = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_epochs):\n",
    "        num_batches = int(X.shape[0] / batch_size)\n",
    "        for b in range(num_batches):\n",
    "            batch_x = X[:(b + 1) * batch_size]\n",
    "            sess.run(optimizer, feed_dict={x_input: batch_x})\n",
    "            if i % 100 == 0:\n",
    "                batch_loss = sess.run(loss, feed_dict={x_input: batch_x})\n",
    "                print(\"Loss: {0}\".format(batch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_encoder(x, lstm_units=2, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope('Encoder'):\n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        lstm_fw = tf.nn.rnn_cell.LSTMCell(lstm_units, initializer=initializer)\n",
    "\n",
    "        outputs, state = tf.nn.dynamic_rnn(lstm_fw, x, dtype=tf.float32)\n",
    "        return state\n",
    "\n",
    "def lstm_decoder(x, z, lstm_units=2, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope('Decoder'):\n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        lstm_fw = tf.nn.rnn_cell.LSTMCell(lstm_units, initializer=initializer)\n",
    "        \n",
    "        zero_tensor = tf.zeros_like(x)\n",
    "        outputs, state = tf.nn.dynamic_rnn(lstm_fw, zero_tensor, initial_state=z)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 30, 29309)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "beta1 = 0.9\n",
    "\n",
    "x_input = tf.placeholder(tf.int32, [None, 30])\n",
    "#embedding = tf.expand_dims(x_input, axis=2)\n",
    "embedding = tf.one_hot(x_input, V)\n",
    "\n",
    "encoder_output = lstm_encoder(embedding, lstm_units=V)\n",
    "decoder_output = lstm_decoder(embedding, encoder_output, lstm_units=V)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(decoder_output - embedding))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "num_epochs = 1000\n",
    "X = X_org\n",
    "batch_size = 100\n",
    "\n",
    "losses = []\n",
    "step = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_epochs):\n",
    "        num_batches = int(X.shape[0] / batch_size)\n",
    "        for b in range(num_batches):\n",
    "            batch_x = X[:(b + 1) * batch_size]\n",
    "            sess.run(optimizer, feed_dict={x_input: batch_x})\n",
    "            \n",
    "            if b % 10 == 0:\n",
    "                loss_i = sess.run(loss, feed_dict={x_input: X})\n",
    "                print(\"Loss: {0}\".format(loss_i))\n",
    "                losses.append(loss_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char-Level LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a mind to strike thee ere thou speak’st.\n",
      "Yet if thou say Antony lives, is well, Or friends wi\n",
      "I have half a mind to hit you before you speak again.\n",
      "But if Antony is alive, healthy, friendly with\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "import os\n",
    "\n",
    "original_dir_path = '../data/shakespeare/original/'\n",
    "modern_dir_path = '../data/shakespeare/modern/'\n",
    "\n",
    "def read_all_files(dir_path):\n",
    "    docs = \"\"\n",
    "    for filename in os.listdir(dir_path):\n",
    "        with open(dir_path + filename, 'r') as file:\n",
    "            docs += file.read()\n",
    "    return docs\n",
    "\n",
    "original_docs = read_all_files(original_dir_path)\n",
    "modern_docs = read_all_files(modern_dir_path)\n",
    "\n",
    "print(original_docs[:100])\n",
    "print(modern_docs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'h', 'a', 'v', 'e', ' ', 'a', ' ', 'm', 'i', 'n', 'd', ' ', 't', 'o', ' ', 's', 't', 'r', 'i', 'k', 'e', ' ', 't', 'h', 'e', 'e', ' ', 'e', 'r', 'e', ' ', 't', 'h', 'o', 'u', ' ', 's', 'p', 'e', 'a', 'k', '’', 's', 't', ' ', 'Y', 'e', 't', ' ', 'i', 'f', ' ', 't', 'h', 'o', 'u', ' ', 's', 'a', 'y', ' ', 'A', 'n', 't', 'o', 'n', 'y', ' ', 'l', 'i', 'v', 'e', 's', ',', ' ', 'i', 's', ' ', 'w', 'e', 'l', 'l', ',', ' ', 'O', 'r', ' ', 'f', 'r', 'i', 'e', 'n', 'd', 's', ' ', 'w', 'i', 't']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode entire dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset = list((original_docs + \" \" + modern_docs).replace(\".\",\"\").replace(\"\\n\", \" \"))\n",
    "print(dataset[:100])\n",
    "\n",
    "enc = LabelEncoder()\n",
    "enc.fit(dataset)\n",
    "V = len(enc.classes_) #size of vocabulary\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinpark/anaconda/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full(200, -1) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matrify_sentences(sentences, encoder, max_length=200):\n",
    "    X = []\n",
    "    for sentence in sentences:\n",
    "        letters = list(sentence)\n",
    "        try:\n",
    "            letters = letters[:max_length]\n",
    "        except:\n",
    "            pass\n",
    "        letters_idx = np.array(encoder.transform(letters))\n",
    "        \n",
    "        arr = np.full(max_length, -1)\n",
    "        arr[:len(letters)] = letters_idx\n",
    "        X.append(arr)\n",
    "    \n",
    "    return np.array(X)\n",
    "\n",
    "\n",
    "original_sentences = original_docs.replace('.',\"\").split('\\n')\n",
    "modern_sentences = modern_docs.replace('.',\"\").split('\\n')\n",
    "\n",
    "X_org = matrify_sentences(original_sentences, enc)\n",
    "X_mod = matrify_sentences(modern_sentences, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "beta1 = 0.9\n",
    "max_length = 20\n",
    "\n",
    "x_input = tf.placeholder(tf.int32, [None, max_length])\n",
    "#embedding = tf.expand_dims(x_input, axis=2)\n",
    "embedding = tf.one_hot(x_input, V)\n",
    "\n",
    "encoder_output = lstm_encoder(embedding, lstm_units=V)\n",
    "decoder_output = lstm_decoder(embedding, encoder_output, lstm_units=V)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(decoder_output - embedding))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/lstm_ae/lstm_ae.ckpt-84000\n",
      "Loss: 0.005685206037014723\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-195-7fb6cbf4342c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinpark/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinpark/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinpark/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/jinpark/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinpark/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "num_epochs = 20\n",
    "X = X_org[:,:max_length]\n",
    "batch_size = 100\n",
    "saved_model_path = '../models/lstm_ae/lstm_ae.ckpt'\n",
    "checkpoint_dir = '../models/lstm_ae/'\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "losses = []\n",
    "step = 0\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        saver.restore(sess, '../models/lstm_ae/lstm_ae.ckpt-84000')\n",
    "    except:\n",
    "        print('No model')\n",
    "        sess.run(init)\n",
    "        \n",
    "    # Train\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        num_batches = int(X.shape[0] / batch_size)\n",
    "        for b in range(num_batches):\n",
    "            batch_x = X[b * batch_size:(b + 1) * batch_size]\n",
    "            sess.run(optimizer, feed_dict={x_input: batch_x})\n",
    "            \n",
    "            if i % 2 == 0 and b == 0:\n",
    "                loss_i = sess.run(loss, feed_dict={x_input: batch_x})\n",
    "                print(\"Loss: {0}\".format(loss_i))\n",
    "                losses.append(loss_i)\n",
    "\n",
    "                saver.save(sess, saved_model_path, global_step=step)\n",
    "            step += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/lstm_ae/lstm_ae.ckpt-0\n",
      "['Pish!', 'So do all thoughts', 'By running fast', 'Tell him there’s a ', 'To who?']\n",
      "['Pisthun caiii;;;;  ', 'So do  at thou loo ', 'By nonnit  aith   o', 'Tell hit theee   rt', 'To shou  connine,  ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinpark/anaconda/lib/python3.5/site-packages/numpy/core/numeric.py:301: FutureWarning: in the future, full(5, -1) will return an array of dtype('int64')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# test AE\n",
    "import numpy as np\n",
    "samples = X[np.random.choice(X.shape[0], size=5)]\n",
    "checkpoint_dir = '../models/lstm_ae/'\n",
    "saved_model_path = '../models/lstm_ae/lstm_ae.ckpt'\n",
    "\n",
    "def textify_samples(x):\n",
    "    x[:,-1] = np.full(x.shape[0], -1)\n",
    "    eos_idx = np.argmin(x, axis=1)\n",
    "    x = [x[i,:eos_idx[i]] for i in range(x.shape[0])]\n",
    "\n",
    "    x_text = [enc.inverse_transform(x[i].astype(int)) for i in range(len(x))]\n",
    "    x_text = [''.join(list(text)) for text in x_text]\n",
    "    return x_text\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    x_generated = sess.run(decoder_output, feed_dict={x_input: samples})\n",
    "    x_generated = np.argmax(x_generated, axis=2)\n",
    "    \n",
    "    print(textify_samples(samples))\n",
    "    print(textify_samples(x_generated))\n",
    "#sess.run(decoder_output, feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Autoencoder with adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x, alpha=0.01):\n",
    "    \"\"\"Compute the leaky ReLU activation function.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: TensorFlow Tensor with arbitrary shape\n",
    "    - alpha: leak parameter for leaky ReLU\n",
    "    \n",
    "    Returns:\n",
    "    TensorFlow Tensor with the same shape as x\n",
    "    \"\"\"\n",
    "    # TODO: implement leaky ReLU\n",
    "    out = tf.maximum(tf.cast(0.0, dtype='float64'), tf.cast(x, dtype='float64'))\n",
    "    out1 = tf.minimum(tf.cast(0.0, dtype='float64'), tf.cast(alpha * x, dtype='float64'))\n",
    "    return tf.cast(out + out1, dtype='float32')\n",
    "\n",
    "def discriminator(x, reuse=False):\n",
    "    \"\"\"Compute discriminator score for a batch of input images.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: TensorFlow Tensor of flattened input images, shape [batch_size, 784]\n",
    "    \n",
    "    Returns:\n",
    "    TensorFlow Tensor with shape [batch_size, 1], containing the score \n",
    "    for an image being real for each input image.\n",
    "    \"\"\"\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope(\"discriminator\"):\n",
    "        # TODO: implement architecture\n",
    "        x = tf.layers.dense(x, 10)\n",
    "        x = leaky_relu(x)\n",
    "        x = tf.layers.dense(x, 10)\n",
    "        x = leaky_relu(x)\n",
    "        x = tf.layers.dense(x, 1)\n",
    "        logits = x\n",
    "        return logits\n",
    "    \n",
    "def lstm_discriminator(x, lstm_units=2, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope('discriminator'):\n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        lstm_fw = tf.nn.rnn_cell.LSTMCell(lstm_units, initializer=initializer)\n",
    "\n",
    "        outputs, state = tf.nn.dynamic_rnn(lstm_fw, x, dtype=tf.float32)\n",
    "        logits = tf.layers.dense(outputs, 1)\n",
    "        return logits\n",
    "    \n",
    "def gan_loss(logits_real, logits_fake):\n",
    "    \"\"\"Compute the GAN loss.\n",
    "    \n",
    "    Inputs:\n",
    "    - logits_real: Tensor, shape [batch_size, 1], output of discriminator\n",
    "        Log probability that the image is real for each real image\n",
    "    - logits_fake: Tensor, shape[batch_size, 1], output of discriminator\n",
    "        Log probability that the image is real for each fake image\n",
    "    \n",
    "    Returns:\n",
    "    - D_loss: discriminator loss scalar\n",
    "    - G_loss: generator loss scalar\n",
    "    \"\"\"\n",
    "    # TODO: compute D_loss and G_loss\n",
    "    labels_real = tf.ones_like(logits_real)\n",
    "    labels_fake = tf.zeros_like(logits_fake)\n",
    "    logits_fake_inv = -logits_fake\n",
    "    \n",
    "    D_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels_real, logits=logits_real) +\n",
    "                            tf.nn.sigmoid_cross_entropy_with_logits(labels=labels_fake, logits=logits_fake))\n",
    "    \n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels_real, logits=logits_fake))\n",
    "\n",
    "    return D_loss, G_loss\n",
    "\n",
    "def get_solvers(learning_rate=1e-3, beta1=0.5):\n",
    "    \"\"\"Create solvers for GAN training.\n",
    "    \n",
    "    Inputs:\n",
    "    - learning_rate: learning rate to use for both solvers\n",
    "    - beta1: beta1 parameter for both solvers (first moment decay)\n",
    "    \n",
    "    Returns:\n",
    "    - D_solver: instance of tf.train.AdamOptimizer with correct learning_rate and beta1\n",
    "    - G_solver: instance of tf.train.AdamOptimizer with correct learning_rate and beta1\n",
    "    \"\"\"\n",
    "    D_solver = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "    G_solver = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "    return D_solver, G_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "beta1 = 0.9\n",
    "max_length = 20\n",
    "\n",
    "x_input = tf.placeholder(tf.int32, [None, None])\n",
    "#embedding = tf.expand_dims(x_input, axis=2)\n",
    "embedding = tf.one_hot(x_input, V)\n",
    "\n",
    "encoder_output = lstm_encoder(embedding, lstm_units=V)\n",
    "decoder_output = lstm_decoder(embedding, encoder_output, lstm_units=V)\n",
    "\n",
    "with tf.variable_scope(\"\") as scope:\n",
    "    logits_real = lstm_discriminator(tf.random_normal(encoder_output))\n",
    "    logits_fake = lstm_discriminator(encoder_output, reuse=True) # might need to predict instead (argmax)\n",
    "\n",
    "D_solver, G_solver = get_solvers()\n",
    "D_loss, G_loss = gan_loss(logits_real, logits_fake)\n",
    "\n",
    "D_train_step = D_solver.minimize(D_loss)\n",
    "G_train_step = G_solver.minimize(G_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textify_samples(x):\n",
    "    x_text = []\n",
    "    for sentence in x:\n",
    "        minimum = np.min(sentence)\n",
    "        if sentence == -1:\n",
    "            eos_idx = np.argmin(sentence)\n",
    "            x_text.append(sentence[:eos_idx])\n",
    "        else:\n",
    "            x_text.append(sentence)\n",
    "    \n",
    "    x_text = [enc.inverse_transform(x_text[i].astype(int)) for i in range(len(x))]\n",
    "    x_text = [''.join(list(text)) for text in x_text]\n",
    "    return x_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_loss: 1.3801724910736084, G_loss: 0.6912965178489685\n",
      "0\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['I', 'k', 'd', 'o', 'Æ', 'Y', 'Æ', 'd', 'R', 'e']\n",
      "D_loss: 1.3460313081741333, G_loss: 0.6997629404067993\n",
      "4\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['I', 'k', 'd', 'o', 'Æ', 'Y', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 1.2840192317962646, G_loss: 0.7229973077774048\n",
      "8\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['I', 'k', 'd', 'o', 'Æ', 'Y', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 1.2166125774383545, G_loss: 0.7491743564605713\n",
      "12\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['I', 'k', 'd', 'o', 'Æ', 'Y', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 1.1366677284240723, G_loss: 0.7664138078689575\n",
      "16\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['T', 'k', 'd', 'o', 'Æ', 'Y', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 1.0826858282089233, G_loss: 0.7708127498626709\n",
      "20\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['T', 'k', 'g', 'o', 'Æ', 'Y', 'Æ', 'g', 'R', '‘']\n",
      "D_loss: 1.0534191131591797, G_loss: 0.7719886302947998\n",
      "24\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['T', 'k', 'g', 'y', 'Æ', 'Y', 'Æ', 'g', 'R', '‘']\n",
      "D_loss: 1.036653757095337, G_loss: 0.7695167064666748\n",
      "28\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['T', 'k', 'g', 'y', 'Æ', 'Y', 'Æ', 'g', 'R', '‘']\n",
      "D_loss: 1.0225986242294312, G_loss: 0.7694975733757019\n",
      "32\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['T', 'k', 'g', 'o', 'Æ', 'Y', 'Æ', 'g', 'R', '‘']\n",
      "D_loss: 1.0129677057266235, G_loss: 0.7679738998413086\n",
      "36\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'g', 'o', 'Æ', 'Y', 'Æ', 'g', 'R', '‘']\n",
      "D_loss: 1.0034140348434448, G_loss: 0.7690957188606262\n",
      "40\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'g', 'o', 'Æ', 'Y', 'Æ', 'g', 'R', '‘']\n",
      "D_loss: 0.9979190826416016, G_loss: 0.7677722573280334\n",
      "44\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'g', 'o', 'Æ', 'Y', 'Æ', 'g', 'R', '‘']\n",
      "D_loss: 0.9895220994949341, G_loss: 0.77156001329422\n",
      "48\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'g', 'o', 'Æ', 'Y', 'Æ', 'g', 'R', '‘']\n",
      "D_loss: 0.988044798374176, G_loss: 0.7687292098999023\n",
      "52\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'g', 'o', 'Æ', 'Y', 'Æ', 'g', 'R', '‘']\n",
      "D_loss: 0.9845912456512451, G_loss: 0.7692233324050903\n",
      "56\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'g', 'o', 'Æ', 'Y', 'Æ', 'g', 'R', '‘']\n",
      "D_loss: 0.9829074740409851, G_loss: 0.7685926556587219\n",
      "60\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'g', 'o', 'Æ', 'Y', 'Æ', 'g', 'R', '‘']\n",
      "D_loss: 0.982062816619873, G_loss: 0.7676567435264587\n",
      "64\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'g', 'o', 'Æ', 'Y', 'Æ', 'g', 'R', 'y']\n",
      "D_loss: 0.9801633358001709, G_loss: 0.7685934901237488\n",
      "68\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'g', 'o', 'Æ', 'Y', 'Æ', 'g', 'R', 'y']\n",
      "D_loss: 0.9797331094741821, G_loss: 0.7681403756141663\n",
      "72\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'Y', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9779391288757324, G_loss: 0.7696731686592102\n",
      "76\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'Y', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9798447489738464, G_loss: 0.7673779129981995\n",
      "80\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'Y', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.979300856590271, G_loss: 0.7680054903030396\n",
      "84\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'Y', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9790773987770081, G_loss: 0.768477201461792\n",
      "88\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9793325066566467, G_loss: 0.7685132026672363\n",
      "92\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9804172515869141, G_loss: 0.7676334977149963\n",
      "96\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.978934109210968, G_loss: 0.7698882818222046\n",
      "100\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9815744757652283, G_loss: 0.76731938123703\n",
      "104\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9808915257453918, G_loss: 0.7687050700187683\n",
      "108\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9826691746711731, G_loss: 0.7673094868659973\n",
      "112\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9823183417320251, G_loss: 0.7683194875717163\n",
      "116\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9818117022514343, G_loss: 0.7694818377494812\n",
      "120\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9835245609283447, G_loss: 0.7680094242095947\n",
      "124\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9841120839118958, G_loss: 0.7678852081298828\n",
      "128\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.984237790107727, G_loss: 0.7681936621665955\n",
      "132\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.983484148979187, G_loss: 0.7695469260215759\n",
      "136\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9860018491744995, G_loss: 0.7670081257820129\n",
      "140\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.984789252281189, G_loss: 0.7688423991203308\n",
      "144\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.9846916794776917, G_loss: 0.769321084022522\n",
      "148\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', 'y']\n",
      "D_loss: 0.986666202545166, G_loss: 0.7674956321716309\n",
      "152\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9871132969856262, G_loss: 0.7672865986824036\n",
      "156\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9865530133247375, G_loss: 0.7681639790534973\n",
      "160\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9858862161636353, G_loss: 0.7691547870635986\n",
      "164\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9863554239273071, G_loss: 0.7688030004501343\n",
      "168\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9875242710113525, G_loss: 0.7676764130592346\n",
      "172\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9870847463607788, G_loss: 0.7683305740356445\n",
      "176\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9867540001869202, G_loss: 0.7688603401184082\n",
      "180\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9868986010551453, G_loss: 0.7688612341880798\n",
      "184\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9881863594055176, G_loss: 0.7675095200538635\n",
      "188\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9882272481918335, G_loss: 0.7675371766090393\n",
      "192\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9872440695762634, G_loss: 0.7686573266983032\n",
      "196\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9866560101509094, G_loss: 0.769336462020874\n",
      "200\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9879645109176636, G_loss: 0.7678307890892029\n",
      "204\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.987947404384613, G_loss: 0.7678792476654053\n",
      "208\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9882454872131348, G_loss: 0.76762855052948\n",
      "212\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9880494475364685, G_loss: 0.7679120898246765\n",
      "216\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9885897040367126, G_loss: 0.7673420310020447\n",
      "220\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9857796430587769, G_loss: 0.7705613374710083\n",
      "224\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9878023862838745, G_loss: 0.768265962600708\n",
      "228\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9869945049285889, G_loss: 0.7691848278045654\n",
      "232\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9877681732177734, G_loss: 0.7682865858078003\n",
      "236\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.988520085811615, G_loss: 0.7674729228019714\n",
      "240\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9873266220092773, G_loss: 0.7689118385314941\n",
      "244\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9887794852256775, G_loss: 0.767103910446167\n",
      "248\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.988330602645874, G_loss: 0.7676397562026978\n",
      "252\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9880175590515137, G_loss: 0.7680178284645081\n",
      "256\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9880564212799072, G_loss: 0.7679476737976074\n",
      "260\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9871817827224731, G_loss: 0.7688347697257996\n",
      "264\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9880706667900085, G_loss: 0.7667457461357117\n",
      "268\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9777847528457642, G_loss: 0.7673838138580322\n",
      "272\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9750017523765564, G_loss: 0.7677651643753052\n",
      "276\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'k', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.9747958779335022, G_loss: 0.7680173516273499\n",
      "280\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'd', 'o', 'Æ', 'é', 'Æ', 'd', 'R', '‘']\n",
      "D_loss: 0.974575400352478, G_loss: 0.7693041563034058\n",
      "284\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'k', 'o', 'Æ', 'é', 'Æ', 'k', 'R', '‘']\n",
      "D_loss: 0.9748332500457764, G_loss: 0.7699207067489624\n",
      "288\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'k', 'o', 'Æ', 'é', 'Æ', 'k', 'R', '‘']\n",
      "D_loss: 0.9756700396537781, G_loss: 0.7694871425628662\n",
      "292\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'k', 'o', 'Æ', 'é', 'Æ', 'k', 'R', '‘']\n",
      "D_loss: 0.976475715637207, G_loss: 0.7685048580169678\n",
      "296\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'k', 'o', 'Æ', 'é', 'Æ', 'k', 'R', '‘']\n",
      "D_loss: 0.9764566421508789, G_loss: 0.767996072769165\n",
      "300\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', 'R', '‘']\n",
      "D_loss: 0.9757979512214661, G_loss: 0.7677649855613708\n",
      "304\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['Q', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9736641049385071, G_loss: 0.7688510417938232\n",
      "308\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['R', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9727345108985901, G_loss: 0.768315851688385\n",
      "312\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['R', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9713869690895081, G_loss: 0.7676765322685242\n",
      "316\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['R', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9682285189628601, G_loss: 0.7679182887077332\n",
      "320\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['5', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9633396863937378, G_loss: 0.7688444256782532\n",
      "324\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['5', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9588684439659119, G_loss: 0.7685561776161194\n",
      "328\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['5', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9537873268127441, G_loss: 0.7686998248100281\n",
      "332\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['5', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9497274160385132, G_loss: 0.76759934425354\n",
      "336\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['5', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9429460167884827, G_loss: 0.7696716785430908\n",
      "340\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['5', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.939625084400177, G_loss: 0.768229603767395\n",
      "344\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['5', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9357389211654663, G_loss: 0.7684038877487183\n",
      "348\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['5', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9312756061553955, G_loss: 0.770332932472229\n",
      "352\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['5', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n",
      "D_loss: 0.9299545884132385, G_loss: 0.7694516777992249\n",
      "356\n",
      "['I', 'Y', 'M', 'W', 'A', 'T', 'C', 'M', 'B', 'F']\n",
      "['5', 'k', 'k', 'o', 'Æ', 'k', 'Æ', 'k', '5', '‘']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-1b7ca5ebac8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurriculum_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD_train_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_train_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;31m#if b % 2 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m#b5 = b / 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinpark/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinpark/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinpark/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/jinpark/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jinpark/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "num_epochs = 1000\n",
    "X = X_org[:,:max_length]\n",
    "batch_size = 1000\n",
    "saved_model_path = '../models/lstm_ae_wa/lstm_ae_wa.ckpt'\n",
    "checkpoint_dir = '../models/lstm_ae_wa/'\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "losses = []\n",
    "step = 0\n",
    "curriculum_size = 1\n",
    "curriculum_error = 0.1\n",
    "with tf.Session() as sess:\n",
    "    #try:\n",
    "        #saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    #except:\n",
    "        #print('No model')\n",
    "    sess.run(init)\n",
    "        \n",
    "    # Train\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        num_batches = int(X.shape[0] / batch_size)\n",
    "        for b in range(num_batches):\n",
    "            batch_x = X[b * batch_size:(b + 1) * batch_size]\n",
    "            batch_x = np.copy(batch_x)[:,:curriculum_size]\n",
    "            \n",
    "            sess.run([D_train_step, G_train_step], feed_dict={x_input: batch_x})\n",
    "            #if b % 2 == 0:\n",
    "                #b5 = b / 2\n",
    "                #x_batch_gen = X[b5 * batch_size:(b5 + 1) * batch_size]\n",
    "                #sess.run(G_train_step, feed_dict={x_input: x_batch_gen})\n",
    "            \n",
    "            if i % 4 == 0 and b == 0:\n",
    "                D_loss_i, G_loss_i = sess.run([D_loss, G_loss], feed_dict={x_input: batch_x})\n",
    "                print(\"D_loss: {0}, G_loss: {1}\".format(D_loss_i, G_loss_i))\n",
    "                losses.append((D_loss_i, G_loss_i))\n",
    "                \n",
    "                x_gen_i = sess.run(decoder_output, feed_dict={x_input: batch_x})\n",
    "                x_gen_i = np.argmax(x_gen_i, axis=2)\n",
    "                print(i)\n",
    "                num_show = 10\n",
    "                print(textify_samples(batch_x[:num_show]))\n",
    "                print(textify_samples(x_gen_i[:num_show]))\n",
    "                \n",
    "                if abs(D_loss_i - G_loss_i) < curriculum_error:\n",
    "                    #curriculum_size += 1\n",
    "                    pass\n",
    "\n",
    "                saver.save(sess, saved_model_path, global_step=step)\n",
    "            step += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZLy+v8BMDAMWTyA/BcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14c785c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "list_d_loss, list_g_loss = [], []\n",
    "for d_loss, g_loss in losses:\n",
    "    list_d_loss.append(d_loss)\n",
    "    list_g_loss.append(g_loss)\n",
    "\n",
    "plt.plot(list_d_loss)\n",
    "plt.plot(list_g_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTMCell' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-e82b36c2d1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LSTMCell' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "lstm = tf.nn.rnn_cell.LSTMCell(2)\n",
    "lstm.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a mind to strike thee ere thou speak’st.\n",
      "Yet if thou say Antony lives, is well, Or friends wi\n",
      "I have half a mind to hit you before you speak again.\n",
      "But if Antony is alive, healthy, friendly with\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "import os\n",
    "\n",
    "original_dir_path = '../data/shakespeare/original/'\n",
    "modern_dir_path = '../data/shakespeare/modern/'\n",
    "\n",
    "def read_all_files(dir_path):\n",
    "    docs = \"\"\n",
    "    for filename in os.listdir(dir_path):\n",
    "        with open(dir_path + filename, 'r') as file:\n",
    "            docs += file.read()\n",
    "    return docs\n",
    "\n",
    "original_docs = read_all_files(original_dir_path)\n",
    "modern_docs = read_all_files(modern_dir_path)\n",
    "\n",
    "print(original_docs[:100])\n",
    "print(modern_docs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'h', 'a', 'v', 'e', ' ', 'a', ' ', 'm', 'i', 'n', 'd', ' ', 't', 'o', ' ', 's', 't', 'r', 'i', 'k', 'e', ' ', 't', 'h', 'e', 'e', ' ', 'e', 'r', 'e', ' ', 't', 'h', 'o', 'u', ' ', 's', 'p', 'e', 'a', 'k', '’', 's', 't', ' ', 'Y', 'e', 't', ' ', 'i', 'f', ' ', 't', 'h', 'o', 'u', ' ', 's', 'a', 'y', ' ', 'A', 'n', 't', 'o', 'n', 'y', ' ', 'l', 'i', 'v', 'e', 's', ',', ' ', 'i', 's', ' ', 'w', 'e', 'l', 'l', ',', ' ', 'O', 'r', ' ', 'f', 'r', 'i', 'e', 'n', 'd', 's', ' ', 'w', 'i', 't']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode entire dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset = list((original_docs + \" \" + modern_docs).replace(\".\",\"\").replace(\"\\n\", \" \"))\n",
    "print(dataset[:100])\n",
    "\n",
    "enc = LabelEncoder()\n",
    "enc.fit(dataset)\n",
    "V = len(enc.classes_) #size of vocabulary\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'a', 'i', 's', 'd', 'f', 'i', 'a', 's', 'f', 'h', 'd']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'haisdfiasfhd'\n",
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matrify_sentences(sentences, encoder, max_length=20):\n",
    "    X = []\n",
    "    for sentence in sentences:\n",
    "        letters = list(sentence)\n",
    "        try:\n",
    "            letters = letters[:max_length]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if letters:\n",
    "            letters_idx = np.array(encoder.transform(letters))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        arr = np.full(max_length, -1)\n",
    "        arr[:len(letters)] = letters_idx\n",
    "        X.append(arr)\n",
    "    \n",
    "    return np.array(X)\n",
    "\n",
    "\n",
    "original_sentences = original_docs.replace('.',\"\").split('\\n')\n",
    "modern_sentences = modern_docs.replace('.',\"\").split('\\n')\n",
    "\n",
    "X_org = matrify_sentences(original_sentences, enc)\n",
    "X_mod = matrify_sentences(modern_sentences, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_encoder(x, lstm_units=2, z_dim=10, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope('Encoder'):\n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        lstm_fw = tf.nn.rnn_cell.LSTMCell(lstm_units, initializer=initializer)\n",
    "\n",
    "        outputs, state = tf.nn.dynamic_rnn(lstm_fw, x, dtype=tf.float32)\n",
    "        c, h = state\n",
    "        z = tf.add(tf.layers.dense(c, z_dim), tf.layers.dense(h, z_dim))\n",
    "        return z\n",
    "\n",
    "def lstm_decoder(x, z, lstm_units=2, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope('Decoder'):\n",
    "        c = tf.layers.dense(z, lstm_units)\n",
    "        h = tf.layers.dense(z, lstm_units)\n",
    "        state = tf.nn.rnn_cell.LSTMStateTuple(c, h)\n",
    "        \n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        lstm_fw = tf.nn.rnn_cell.LSTMCell(lstm_units, initializer=initializer)\n",
    "        \n",
    "        zero_tensor = tf.zeros_like(x)\n",
    "        outputs, state = tf.nn.dynamic_rnn(lstm_fw, zero_tensor, initial_state=state)\n",
    "        return outputs\n",
    "\n",
    "def lstm_decoder_teacher_forced(x, z, lstm_units=2, training=True, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope('Decoder'):\n",
    "        c = tf.layers.dense(z, lstm_units)\n",
    "        h = tf.layers.dense(z, lstm_units)\n",
    "        state = tf.nn.rnn_cell.LSTMStateTuple(c, h)\n",
    "        \n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        lstm_fw = tf.nn.rnn_cell.LSTMCell(lstm_units, initializer=initializer)\n",
    "        \n",
    "        if training:\n",
    "            go_vector = tf.fill([tf.shape(x)[0], tf.constant(1, dtype=int32)], -1)\n",
    "            x_shifted_right = tf.stack([go_vector, x[:,:-1]]) \n",
    "            \n",
    "            outputs, state = tf.nn.dynamic_rnn(lstm_fw, x_shifted_right, initial_state=state)\n",
    "            return outputs\n",
    "        else:\n",
    "            input_tensor = tf.fill(tf.shape(x)[0], -1)\n",
    "            outputs = []\n",
    "            for _ in range(lstm_units):\n",
    "                input_tensor, state = tf.nn.dynamic_rnn(lstm_fw, input_tensor, initial_state=state)\n",
    "                outputs.append(input_tensor)\n",
    "            return tf.stack(outputs, axis=1)\n",
    "\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    \"\"\"Compute the leaky ReLU activation function.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: TensorFlow Tensor with arbitrary shape\n",
    "    - alpha: leak parameter for leaky ReLU\n",
    "    \n",
    "    Returns:\n",
    "    TensorFlow Tensor with the same shape as x\n",
    "    \"\"\"\n",
    "    # TODO: implement leaky ReLU\n",
    "    out = tf.maximum(tf.cast(0.0, dtype='float64'), tf.cast(x, dtype='float64'))\n",
    "    out1 = tf.minimum(tf.cast(0.0, dtype='float64'), tf.cast(alpha * x, dtype='float64'))\n",
    "    return tf.cast(out + out1, dtype='float32')\n",
    "\n",
    "def discriminator(x, reuse=False):\n",
    "    \"\"\"Compute discriminator score for a batch of input images.\n",
    "    \n",
    "    Inputs:\n",
    "    - x: TensorFlow Tensor of flattened input images, shape [batch_size, 784]\n",
    "    \n",
    "    Returns:\n",
    "    TensorFlow Tensor with shape [batch_size, 1], containing the score \n",
    "    for an image being real for each input image.\n",
    "    \"\"\"\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope(\"discriminator\"):\n",
    "        # TODO: implement architecture\n",
    "        x = tf.layers.dense(x, 10)\n",
    "        x = leaky_relu(x)\n",
    "        x = tf.layers.dense(x, 10)\n",
    "        x = leaky_relu(x)\n",
    "        x = tf.layers.dense(x, 1)\n",
    "        logits = x\n",
    "        return logits\n",
    "    \n",
    "def lstm_discriminator(x, lstm_units=2, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope('discriminator'):\n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        lstm_fw = tf.nn.rnn_cell.LSTMCell(lstm_units, initializer=initializer)\n",
    "\n",
    "        outputs, state = tf.nn.dynamic_rnn(lstm_fw, x, dtype=tf.float32)\n",
    "        logits = tf.layers.dense(outputs, 1)\n",
    "        return logits\n",
    "    \n",
    "def gan_loss(logits_real, logits_fake):\n",
    "    \"\"\"Compute the GAN loss.\n",
    "    \n",
    "    Inputs:\n",
    "    - logits_real: Tensor, shape [batch_size, 1], output of discriminator\n",
    "        Log probability that the image is real for each real image\n",
    "    - logits_fake: Tensor, shape[batch_size, 1], output of discriminator\n",
    "        Log probability that the image is real for each fake image\n",
    "    \n",
    "    Returns:\n",
    "    - D_loss: discriminator loss scalar\n",
    "    - G_loss: generator loss scalar\n",
    "    \"\"\"\n",
    "    # TODO: compute D_loss and G_loss\n",
    "    labels_real = tf.ones_like(logits_real)\n",
    "    labels_fake = tf.zeros_like(logits_fake)\n",
    "    logits_fake_inv = -logits_fake\n",
    "    \n",
    "    D_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels_real, logits=logits_real) +\n",
    "                            tf.nn.sigmoid_cross_entropy_with_logits(labels=labels_fake, logits=logits_fake))\n",
    "    \n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels_real, logits=logits_fake))\n",
    "\n",
    "    return D_loss, G_loss\n",
    "\n",
    "def get_solvers(learning_rate=1e-3, beta1=0.5):\n",
    "    \"\"\"Create solvers for GAN training.\n",
    "    \n",
    "    Inputs:\n",
    "    - learning_rate: learning rate to use for both solvers\n",
    "    - beta1: beta1 parameter for both solvers (first moment decay)\n",
    "    \n",
    "    Returns:\n",
    "    - D_solver: instance of tf.train.AdamOptimizer with correct learning_rate and beta1\n",
    "    - G_solver: instance of tf.train.AdamOptimizer with correct learning_rate and beta1\n",
    "    \"\"\"\n",
    "    D_solver = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "    G_solver = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "    return D_solver, G_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_decoder_teacher_forced(x, z, max_length, lstm_units=2, training=True, reuse=False, softmax=True):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.variable_scope('Decoder', reuse=reuse):\n",
    "        c = tf.layers.dense(z, lstm_units)\n",
    "        h = tf.layers.dense(z, lstm_units)\n",
    "        state = tf.nn.rnn_cell.LSTMStateTuple(c, h)\n",
    "        \n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        lstm_fw = tf.nn.rnn_cell.LSTMCell(lstm_units, initializer=initializer)\n",
    "        \n",
    "        if training:\n",
    "            with tf.name_scope('Training'):\n",
    "                go_vector = tf.fill([tf.shape(x)[0], 1, lstm_units], 0)\n",
    "                go_vector = tf.cast(go_vector, tf.float32)\n",
    "\n",
    "                x_shifted_right = tf.concat([go_vector, x[:,:-1,:]], axis=1)\n",
    "\n",
    "                outputs, state = tf.nn.dynamic_rnn(lstm_fw, x_shifted_right, initial_state=state)\n",
    "                return outputs\n",
    "        else:\n",
    "            with tf.name_scope('Inference'):\n",
    "                input_tensor = tf.fill([tf.shape(x)[0], 1, lstm_units], 0.0)\n",
    "                outputs = []\n",
    "                for i in range(max_length):\n",
    "                    input_tensor, state = tf.nn.dynamic_rnn(lstm_fw, input_tensor, initial_state=state)\n",
    "                    outputs.append(input_tensor)\n",
    "                    \n",
    "                    # use labels, not softmax\n",
    "                    if not softmax:\n",
    "                        input_tensor = tf.argmax(input_tensor, axis=2)\n",
    "                        input_tensor = tf.one_hot(input_tensor, lstm_units, axis=2)\n",
    "                return tf.concat(outputs, axis=1)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "beta1 = 0.9\n",
    "max_length = 20\n",
    "z_dim = 100\n",
    "lambda_g = 0\n",
    "\n",
    "x_input = tf.placeholder(tf.int32, [None, None])\n",
    "embedding = tf.one_hot(x_input, V)\n",
    "\n",
    "encoder_output = lstm_encoder(embedding, lstm_units=V, z_dim=z_dim)\n",
    "with tf.variable_scope(\"\") as scope:\n",
    "    decoder_output = lstm_decoder_teacher_forced(embedding, encoder_output, max_length, lstm_units=V)\n",
    "    decoder_output_inf = lstm_decoder_teacher_forced(embedding, encoder_output, max_length, training=False, reuse=True, lstm_units=V, softmax=False)\n",
    "\n",
    "#with tf.variable_scope(\"\") as scope:\n",
    "    #logits_real = discriminator(tf.random_normal(tf.shape(encoder_output)))\n",
    "    #logits_fake = discriminator(encoder_output, reuse=True) # might need to predict instead (argmax)\n",
    "                                                                                                                                                                                                                              \n",
    "_, G_solver = get_solvers()\n",
    "#D_loss, G_loss = gan_loss(logits_real, logits_fake)\n",
    "G_loss = tf.reduce_mean(tf.square(decoder_output - embedding))\n",
    "G_loss_inf = tf.reduce_mean(tf.square(decoder_output_inf - embedding))\n",
    "\n",
    "#G_loss = tf.reduce_mean(tf.square(decoder_output_inf - embedding)) + lambda_g * G_loss\n",
    "\n",
    "#D_train_step = D_solver.minimize(D_loss)\n",
    "G_train_step = G_solver.minimize(G_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textify_samples(x):\n",
    "    x_text = []\n",
    "    for sentence in x:\n",
    "        minimum = np.min(sentence)\n",
    "        if minimum == -1:\n",
    "            eos_idx = np.argmin(sentence)\n",
    "            x_text.append(sentence[:eos_idx])\n",
    "        else:\n",
    "            x_text.append(sentence)\n",
    "    \n",
    "    x_text = [enc.inverse_transform(x_text[i].astype(int)) for i in range(len(x))]\n",
    "    x_text = [''.join(list(text)) for text in x_text]\n",
    "    return x_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/lstm_ae_wa/lstm_ae_wa.ckpt-2100000\n",
      "loss_train: 0.0015865793684497476, loss_inf: 0.005917215254157782\n",
      "0\n",
      "['Rogue, thou hast liv', 'What mean you, madam', 'The gods confound th', 'Free, madam, no', 'Which do not be entr']\n",
      "['Gouue, thou hast liv', 'What mean you, madam', 'The gods concound th', 'Free, madam, novvvvv', 'Whilh do not be entr']\n",
      "['Godg, elit IashClea ', 'What mean you, madam', 'The gods concound lt', 'Free, madam, novitso', 'Whil ho It, oned r e']\n",
      "loss_train: 0.0015558437444269657, loss_inf: 0.0057899500243365765\n",
      "5\n",
      "['Dost thou hold there', 'Though I am mad, I w', 'Tis no matter— Go to', 'Lead me from hence', 'I will not hurt him']\n",
      "['Dost thou hold there', 'Though I am mad, I w', 'Tis no matter  Io to', 'Lead me mrom hence h', 'I will not hurt him ']\n",
      "['Dost thou hold there', 'Though I am mad, I w', 'Tis no matter tom nt', 'Lead me mye celven d', 'I will not hurt him ']\n",
      "loss_train: 0.0015514205442741513, loss_inf: 0.005761658772826195\n",
      "10\n",
      "['Many times, madam', 'No, you shall paint ', 'I am paid for ’t now', 'Which do not be entr', 'Madam, he’s married ']\n",
      "['Many times, madam,,s', 'No, you shall aaint ', 'I am aaid for It now', 'Whilh do not be entr', 'Madam, hems married ']\n",
      "['Many times, madam, s', 'No, you shall anit h', 'I am andim to tnal r', 'Whil ho It, one dre ', 'Madam, hem sarmirde ']\n",
      "loss_train: 0.0015091379173099995, loss_inf: 0.00563876423984766\n",
      "15\n",
      "['The gods confound th', 'Free, madam, no', 'I will not hurt him', 'Get thee hence', 'Get thee hence']\n",
      "['The gods concound th', 'Free, madam, novfmmm', 'I will not hurt him ', 'Get thee hencensssss', 'Get thee hencensssss']\n",
      "['The gods concolu dnt', 'Free, madam, noviest', 'I will not hurt him ', 'Get thee hencenm tal', 'Get thee hencenm tal']\n",
      "loss_train: 0.0014777585165575147, loss_inf: 0.0056118834763765335\n",
      "20\n",
      "['I have done my duty', 'I crave your highnes', 'Hence, horrible vill', 'He’s friends with Ca', 'Thou shalt be whippe']\n",
      "['I have done my duty ', 'I prave your highnes', 'Hence, horrirle will', 'He’s griends with aa', 'Thou shalt be whigee']\n",
      "['I have done my duty ', 'I piate loy mirg ghn', 'Hence, horrire himll', 'He’s goileng stuiw e', 'Thou shalt be whigon']\n",
      "loss_train: 0.0014637638814747334, loss_inf: 0.005481047090142965\n",
      "25\n",
      "['Give to a gracious m', 'Lead me to my chambe', 'The blow thou hadst ', 'Yet if thou say Anto', 'Give to a gracious m']\n",
      "['Give to a gracious m', 'Lead me to my chamee', 'The klow thou hadst ', 'Yet if thou say nnto', 'Give to a gracious m']\n",
      "['Give to a gracious m', 'Lead me to my chame ', 'The kyo dwel ay hiet', 'Yet if thou say not ', 'Give to a gracious m']\n",
      "loss_train: 0.0015296112978830934, loss_inf: 0.0052261147648096085\n",
      "30\n",
      "['For what good turn?', 'The beds i’ th’ East', 'I crave your highnes', 'Oh, that his fault s', 'Thou canst not fear ']\n",
      "['For what good turn?(', 'The beds iP tha aast', 'I prave your highnes', 'Oh, that his fault s', 'Thou canst not fear ']\n",
      "['For what good turn?(', 'The beds iP’t han ut', 'I paite loy riggh na', 'Oh, that his fault s', 'Thou canst not fear ']\n",
      "loss_train: 0.0014180884463712573, loss_inf: 0.0051778280176222324\n",
      "35\n",
      "['The most infectious ', 'He is married?', 'Lead me to my chambe', 'But yet, madam— I do', 'For the best turn i’']\n",
      "['The most infectious ', 'He is married?—pvAPP', 'Lead me to my chamee', 'But yet, madamy I do', 'For the best turn iv']\n",
      "['The most infectious ', 'He is married?— ogsh', 'Lead me to my chame ', 'But yet, madamy e It', 'For the best turn iv']\n",
      "loss_train: 0.001383781316690147, loss_inf: 0.005106701515614986\n",
      "40\n",
      "['For what good turn?', 'These hands do lack ', 'Say ’tis not so, a p', 'Pray, then, foresee ', 'He is married?']\n",
      "['For what good turno(', 'These hands do lack ', 'Say ttis not so, a w', 'Pray, then, foresee ', 'He is married?)pvAAA']\n",
      "['For what good turnog', 'These hands do lack ', 'Say tio nsgot o nou,', 'Pray, then, foresee ', 'He is married?) Iswe']\n",
      "loss_train: 0.0013922455254942179, loss_inf: 0.00513515155762434\n",
      "45\n",
      "['Well said', 'Madam, he’s married ', 'I make not, but fore', 'O Iras, Charmian!', 'The blow thou hadst ']\n",
      "['Well said  AAAgggvvv', 'Madam, hems married ', 'I make not, but fore', 'O sras, hharmian,–,,', 'The klow thou hadst ']\n",
      "['Well said pogeat yoe', 'Madam, hemas romireg', 'I make not, but fore', 'O sar, I’shalig arno', 'The kyo dwet haishd ']\n",
      "loss_train: 0.001427769660949707, loss_inf: 0.005160970613360405\n",
      "50\n",
      "['Bid him Report the f', 'Tis no matter— Go to', 'Bid him Report the f', 'He is married?', 'Some innocents ’scap']\n",
      "['Bid him meport the f', 'Tis no matter  Io to', 'Bid him meport the f', 'He is married?—)vAAA', 'Some innocents sscad']\n",
      "['Bid him metn trofe t', 'Tis no matter tom n ', 'Bid him metn trofe t', 'He is married?— ogsh', 'Some innocents samyn']\n",
      "loss_train: 0.0014015911146998405, loss_inf: 0.005287031177431345\n",
      "55\n",
      "['The most infectious ', 'That’s our offer', 'Take no offense that', 'Madam, he’s well', 'I made no such repor']\n",
      "['The most infectious ', 'That’s our offereeyy', 'Take no offense that', 'Madam, hews welllggy', 'I dade no such rerrr']\n",
      "['The most infectious ', 'That’s our offerey a', 'Take no offense that', 'Madam, hewe sallder ', 'I dma en sout hmerin']\n",
      "loss_train: 0.0013796741841360927, loss_inf: 0.004949747584760189\n",
      "60\n",
      "['Free, madam, no', 'What say you?', 'We’ll speak with the', 'I have made no fault', 'You shall be more be']\n",
      "['Free, madam, novdvvk', 'What say you —)PP!!P', 'We’ll seeak with the', 'I have made no fault', 'You shall be more be']\n",
      "['Free, madam, novits ', 'What say you sadne m', 'We’ll seawe ik‘thy t', 'I have made no fault', 'You shall be more be']\n",
      "loss_train: 0.0013604041887447238, loss_inf: 0.005030036438256502\n",
      "65\n",
      "['He is afeard to come', 'Take no offense that', 'Lord Alexas, sweet A', 'Oh that I knew this ', 'In praising Antony, ']\n",
      "['He is afeard to come', 'Take no offense that', 'Lord lleaas, sweet b', 'Oh that I knew this ', 'In praising bntony, ']\n",
      "['He is afeard to come', 'Take no offense that', 'Lord leas me,ast see', 'Oh that I knew this ', 'In praising bltnons ']\n",
      "loss_train: 0.001314502558670938, loss_inf: 0.004907029215246439\n",
      "70\n",
      "['Get thee hence', 'Lead me from hence', 'The gods confound th', 'Which do not be entr', 'We’ll speak with the']\n",
      "['Get thee henceMggPP ', 'Lead me from hencect', 'The gods confound th', 'Which do not be entr', 'We’ll seeak with the']\n",
      "['Get thee henceMar sh', 'Lead me from hencecr', 'The gods confound th', 'Which do not be entr', 'We’ll seawk bunt hte']\n",
      "loss_train: 0.0013733714586123824, loss_inf: 0.004779651295393705\n",
      "75\n",
      "['Vex not his prescien', 'But yet, madam— I do', 'Bid him Report the f', 'Nay then, I’ll run', 'Hence, horrible vill']\n",
      "['Ve  not his rresiien', 'But yet, madam  I do', 'Bid him meport the f', 'Nay then, I’ll runco', 'Hence, horrible will']\n",
      "['Ve neo yth ies slie,', 'But yet, madam do I ', 'Bid him metn torf th', 'Nay then, I’ll runcr', 'Hence, horrible will']\n",
      "loss_train: 0.0013193313498049974, loss_inf: 0.004845388233661652\n",
      "80\n",
      "['Though it be honest,', 'Say ’tis not so, a p', 'Come hither, sir', 'I make not, but fore', 'Call!']\n",
      "['Though it be honest,', 'Say ttis not so, a p', 'Come hither, sir\\u2003haa', 'I make not, but fore', 'Call!—PA!!PPPPPPPccP']\n",
      "['Though it be honest,', 'Say tio ngsot o nam,', 'Come hither, sir\\u2003\\u2003\\u2003\\u2003', 'I make not, but fore', 'Call!— ongum, tonle ']\n",
      "loss_train: 0.0012877349508926272, loss_inf: 0.0048569682985544205\n",
      "85\n",
      "['Be attentive', 'I make not, but fore', 'The most infectious ', 'Hush!', 'Dost thou hold there']\n",
      "['Be attentive  TPTrrr', 'I make not, but fore', 'The most infectious ', 'Hushe—PPPPPPPPPPPPPP', 'Dost thou hold there']\n",
      "['Be attentive ogptoi ', 'I make not, but fore', 'The most infectious ', 'Hushe yave, tgoides ', 'Dost thou hold there']\n",
      "loss_train: 0.0013047830434516072, loss_inf: 0.004734336398541927\n",
      "90\n",
      "['You shall be more be', 'The beds i’ th’ East', 'You have made me off', 'Thou canst not fear ', 'I will not hurt him']\n",
      "['You shall be more be', 'The beds iP the aast', 'You have made me off', 'Thou canst not fear ', 'I will not furt hima']\n",
      "['You shall be more be', 'The beds iPed ant ho', 'You have made me off', 'Thou canst not fear ', 'I will not fry heiga']\n",
      "loss_train: 0.0012433782685548067, loss_inf: 0.004690848290920258\n",
      "95\n",
      "['We’ll speak with the', 'He’s married, madam', 'In praising Antony, ', 'We’ll speak with the', 'In praising Antony, ']\n",
      "['We’ll seeak with the', 'He’s married, madame', 'In praising tntony, ', 'We’ll seeak with the', 'In praising tntony, ']\n",
      "['We’ll seawk blit hth', 'He’s married, madame', 'In praising tonny ut', 'We’ll seawk blit hth', 'In praising tonny ut']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train: 0.0012787207961082458, loss_inf: 0.0045881615951657295\n",
      "100\n",
      "['Fie upon “But yet” “', 'Free, madam, no', 'Be pleased to tell u', 'Take no offense that', 'This ’greed upon To ']\n",
      "['Fie unon bbut yetc c', 'Free, madam, novdvWW', 'Be wleased to tell u', 'Take no offense that', 'This ggreed uron Io ']\n",
      "['Fie unovGut nout glo', 'Free, madam, novitas', 'Be welaces dr toe lh', 'Take no offense that', 'This goregde yat ofn']\n",
      "loss_train: 0.0014091841876506805, loss_inf: 0.004882559180259705\n",
      "105\n",
      "['I’ll unhair thy head', 'I have made no fault', 'The merchandise whic', 'The man is innocent', 'Be attentive']\n",
      "['I’ll hnhair thy head', 'I have made no fault', 'The merchandise whic', 'The man is innocento', 'Be attentive eeP’‘‘u']\n",
      "['I’ll huanir th hidse', 'I have made no fault', 'The merchandise whic', 'The man is innocento', 'Be attentive eyog, l']\n",
      "loss_train: 0.001215719268657267, loss_inf: 0.004574879072606564\n",
      "110\n",
      "['I have made no fault', 'At land indeed Thou ', 'I did not think, sir', 'Let me have your han', 'Madam, he’s married ']\n",
      "['I have made no fault', 'At land indeed hhou ', 'I did not think, sir', 'Let me have your han', 'Madam, he?s married ']\n",
      "['I have made no fault', 'At land indeed hou t', 'I did not think, sir', 'Let me have your han', 'Madam, he?) rs mfain']\n",
      "loss_train: 0.0012011757353320718, loss_inf: 0.004609556403011084\n",
      "115\n",
      "['Take your time', 'Give to a gracious m', 'That’s our offer', 'He’s bound unto Octa', 'Thou shalt be whippe']\n",
      "['Take your time dvvvv', 'Give to a gracious m', 'That’s our offereeeo', 'He’s oound unto ccta', 'Thou shalt be whimee']\n",
      "['Take your time denas', 'Give to a gracious m', 'That’s our offere ya', 'He’s or di,mntt acor', 'Thou shalt be whimen']\n",
      "loss_train: 0.0012171983253210783, loss_inf: 0.00463823601603508\n",
      "120\n",
      "['What say you?', 'Bring me word how ta', 'Lead me from hence', 'Bring me word how ta', 'Good madam, keep you']\n",
      "['What say you?——TTTPP', 'Bring me word how ta', 'Lead me from hence’f', 'Bring me word how ta', 'Good madam, keed you']\n",
      "['What say you?— ogosg', 'Bring me word how ta', 'Lead me from hence’t', 'Bring me word how ta', 'Good madam, keed yoa']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ab8e7c89da21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurriculum_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mG_train_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;31m#if b % 2 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m#b5 = b / 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "num_epochs = 1000\n",
    "X = X_org[:,:max_length]\n",
    "batch_size = 100\n",
    "saved_model_path = '../models/lstm_ae_wa/lstm_ae_wa.ckpt'\n",
    "checkpoint_dir = '../models/lstm_ae_wa/'\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "losses = []\n",
    "step = 0\n",
    "curriculum_size = 20\n",
    "curriculum_error = 0.2\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    except:\n",
    "        print('No model')\n",
    "        sess.run(init)\n",
    "        \n",
    "    # Train\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        num_batches = int(X.shape[0] / batch_size)\n",
    "        for b in range(num_batches):\n",
    "            batch_x = X[b * batch_size:(b + 1) * batch_size]\n",
    "            batch_x = np.copy(batch_x)[:,:curriculum_size]\n",
    "            \n",
    "            sess.run([G_train_step], feed_dict={x_input: batch_x})\n",
    "            #if b % 2 == 0:\n",
    "                #b5 = b / 2\n",
    "                #x_batch_gen = X[b5 * batch_size:(b5 + 1) * batch_size]\n",
    "                #sess.run(G_train_step, feed_dict={x_input: x_batch_gen})\n",
    "            \n",
    "            if i % 5 == 0 and b == 0:\n",
    "                D_loss_i, G_loss_i = sess.run([G_loss, G_loss_inf], feed_dict={x_input: X})\n",
    "                print(\"loss_train: {0}, loss_inf: {1}\".format(D_loss_i, G_loss_i))\n",
    "                losses.append((D_loss_i, G_loss_i))\n",
    "                \n",
    "                x_gen_i = sess.run(decoder_output, feed_dict={x_input: batch_x})\n",
    "                x_gen_i = np.argmax(x_gen_i, axis=2)\n",
    "                x_gen_i_inf = sess.run(decoder_output_inf, feed_dict={x_input: batch_x})\n",
    "                x_gen_i_inf = np.argmax(x_gen_i_inf, axis=2)\n",
    "                \n",
    "                print(i)\n",
    "                num_show = 5\n",
    "                show_idx = np.random.choice(batch_x.shape[0], size=num_show)\n",
    "                print(textify_samples(batch_x[show_idx]))\n",
    "                print(textify_samples(x_gen_i[show_idx]))\n",
    "                print(textify_samples(x_gen_i_inf[show_idx]))\n",
    "\n",
    "                saver.save(sess, saved_model_path, global_step=step)\n",
    "            step += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8Fed97/HPT0f7ggRasEASiyGO8QLYMmA7zeYkxk4c\nmsRJwMRxEjs4qd0mbW9bu729N9f3ld74Njdp2sZJvMW7sUPihiZ1HL+yxwaBABsbMLYMAsSiBe1C\nOtp+948ZgRASHC2g7ft+veZ1ZuY8c87z+Jj5amaeecbcHRERkbjRroCIiIwNCgQREQEUCCIiElIg\niIgIoEAQEZGQAkFERAAFgoiIhBQIIiICKBBERCQUP9oVGIycnByfPXv2aFdDRGTc2LJlS42758ZS\ndlwFwuzZsyktLR3taoiIjBtmti/WsjplJCIiQIyBYGbLzWy3mZWZ2V39vJ9kZs+E75eY2exe790d\nrt9tZtf2Wp9lZuvM7A0z22VmV45Eg0REZGjOGAhmFgG+C1wHLABWmdmCPsVuBercfR7wbeDecNsF\nwErgImA5cF/4eQDfAX7h7u8EFgK7ht8cEREZqliOEJYAZe6+x93bgbXAij5lVgCPhvPrgGvMzML1\na9096u57gTJgiZlNAd4NPATg7u3uXj/85oiIyFDFEggzgQO9livCdf2WcfdOoAHIPs22c4Fq4Idm\nts3MHjSztCG1QERERkQsgWD9rOv7VJ2Bygy0Ph64DPieuy8GWoBTrk0AmNkaMys1s9Lq6uoYqisi\nIkMRSyBUAIW9lguAQwOVMbN4IBOoPc22FUCFu5eE69cRBMQp3P1+dy929+Lc3Ji60oqIyBDEEgib\ngflmNsfMEgkuEq/vU2Y9cEs4fyPwaw+ezbkeWBn2QpoDzAc2ufsR4ICZXRBucw2wc5htGdC//uot\nfv9mNd3delyoiMhAznhjmrt3mtmdwAtABHjY3XeY2T1AqbuvJ7g4/LiZlREcGawMt91hZs8S7Ow7\ngTvcvSv86D8HngxDZg/w+RFuGwDN0U4e37iPb734JnNy0rh52SxuLC5gSnLC2fg6EZFxy4I/5MeH\n4uJiH8qdytHOLp5/7QiPbShn6/56UhMjfGzxTD575WwuOC9j5CsqIjJGmNkWdy+OqexkCITeXqto\n4LEN5ax/9RDRzm6WzpnGLVfN5oMLppMQ0Y3bIjKxKBBiUNfSzrOlB3h84z4q6lqZPiWJ1UtnsXJJ\nIXkZySPyHSIio02BMAhd3c5v3qjisY37+P2b1SREjOsuzuempUW8Y3oGWSkJxMX113tWRGTsG0wg\njKvRTs+GSJzxgQXT+cCC6eypbubxjftYV1rB+leDnrXxcUZ2eiK5GUnkpicFr8fnk8npeS8jifSk\neIIbtEVExp9Jf4TQn5ZoJ394q5ojDW1UN0epbgqn5ig1Te3UNEfp7KcLa35mMp8qLmTlkkLyM1PO\nej1FRM5Ep4zOsu5up761o1dQtFHVGGXDnqP87s1qDLjmwumsXlrEu+fn6pSTiIwaBcIoOlB7jKc3\n7efZ0gPUNLdTOC2FVUuK+OTlheRmJI129URkklEgjAHtnd38cucRnty4nw17jpIQMa696DxWL53F\nsrnTdK1BRM4JBcIYU1bVzNOb9rNuSwUNrR3MzU1j9dJZfOKymWSlJo529URkAlMgjFFtHV38fPth\nnizZx9b99STFx3Fh/hRy0pPISU888ZqRRHZaErkZwbrMlAQdUYjIkKjb6RiVnBDhE5cX8InLC9h5\nqJFnSw/wdnUzB+tbebWintqWdrr66b3U0/U1Jz2J86Ykc8PCGVx/ST6J8bqzWkRGjo4QxpDubqfu\nWDtHW9qp6enm2tzO0eYoNeH8W1VNHKhtJS8jic8sm8VNS4vISdfFahHpn04ZTWDd3c7v3qrmkZfK\n+d2b1SRG4rhh4Qw+f/VsLp6ZOdrVE5ExRqeMJrC4OON9F+TxvgvyKKtq5tGXy/nx1gp+vLWCK2ZP\n5fNXz+FDC6YTr4H6RGSQdIQwATS0dvCj0gM88nI5FXWtzMhM5uYrZ7NqSaF6MYlMcjplNEl1dTu/\n2lXJD18qZ8OeoyQnxPGxxTO59V1zmJen5z6ITEYKBGHX4UYeeamc/3jlIO7wjU9cwscvKxjtaonI\nOTaYQNCJ5gnqwvwp3Hvjpbx01/u5fNZU/urZV/nmC7v1XGkRGZACYYLLSU/isVuXsGpJIf/+mzLu\nfHorre1dZ95QRCYdBcIkkBCJ458+dgn//cMX8vzrR/j0/RuobGwb7WqJyBijQJgkzIzb/mQuD9xc\nzNtVzaz495d4/WDDaFdLRMYQBcIk84EF01n35auIxBmf/P4GXthxZLSrJCJjhAJhErowfwrP3XEV\nF5yXwZee2ML3fvs246m3mYicHQqESSovI5m1a5bx4UvyufcXb/A367bT3tk92tUade5OW4cuusvk\npKErJrHkhAj/tmox5+em851fvcX+2mN8/zOXMy1t8t3d3Bzt5LmtFTy+cR+H6tt48ralLCzMGu1q\niZxTOkKY5MyMv/zgO/jOykW8cqCej933EmVVzaNdrXPmrcom/sdPX2fZP/2Kf/zpDhLj48hMSeAL\nj2xmb03LaFdP5JzSncpy3Nb9dax5rJRoZzd/9t55XHBeOvNyM5g5NYVI3MR5QE9HVzcv7qzksQ3l\nbNxTS2Ikjo9cms/NV85iUWEWe2tauPH7G0hLivCTL1+tZ2HLuKahK2TIKuqO8WdPbmV7xYkuqUnx\ncczNTef83DTm5aUfn+bkpJEUHxnF2g5OVWMbT23az9Ob9lPZGGVmVgqfWTaLTxUXkN3nmRLb9tdx\n0wMlnJ+Xxto1V5KepLOrMj4pEGTY6o+1U1bVfHx6u7qZsupmKupa6flfJs6gaFoq8/LSOT8vncWF\nUymePXVMPbDH3SnZW8vjG/bxwo4jdHY773lHLp+9chbvvSDvtEc+v3mjitseK+Wq87N56JYr9IQ6\nGZcUCHLWtLZ3sacmDImqZt6ubqGsqpm9NS20dwW9lObmpFE8eypXzJ7GFbOnMSs79aw8E7qto4ua\n5ihHm9s52tLzdLl2aluCdTUt7ew72sK+o8fITEngU8UFrF46i9k5aTF/x49KD/A367bzp4tm8K1P\nLSJuAp06k8lBD8iRsyYlMcJFMzK5aMbJT2eLdnbx+sEGNpfXUVpeyy93VvJsaQUQjKd0xeypFM+e\nxhWzp7Igf8qAD/Bp6+iiuilKVVOU6vAxotVNJ6aj4c7+aHOUlgHGZEpOiCMnPYns9CTm56Vzx3vn\nccPCGaQkDv701ieLC6lqivLPL+xm+pRk7r7+wkF/hsh4oUCQEZEUH+HyWdO4fNY0eM/5dHc7b1c3\nHw+ITeW1PP96cFd0amKExUVZnJ+bTm1L+4kdf2OUpmjnKZ9tBtlpieSkJ5GbkcSsaalkpyeRnZ5I\nTlrwmp2eRHZaItnpiaQmjuz/1n/23vOpbGzjB7/fQ25GErf9ydwR/XyRsUKnjOScOdzQSmkYEJvL\n6zhQe4ycjCRywx39KVN6EnkZSUxLSxz1R4J2dTt3PrWV518/wr+uWsxHF84Y1fqIxGrETxmZ2XLg\nO0AEeNDdv9Hn/STgMeBy4CjwaXcvD9+7G7gV6AL+wt1fCNeXA03h+s5YKyzjV35mCjcsTOGGcbgz\njcQZ3/70Io62bOKvn32FnLRErpqXM9rVEhlRZ/yzy8wiwHeB64AFwCozW9Cn2K1AnbvPA74N3Btu\nuwBYCVwELAfuCz+vx/vcfZHCQMaD5IQID3y2mLk56ax5fAs7Dg1ttNjGtg5eKquhrqV9hGsoMjyx\nHCEsAcrcfQ+Ama0FVgA7e5VZAXwtnF8H/LsF3UpWAGvdPQrsNbOy8PM2jEz1Rc6tzJQEHvnCFXz8\nvpf53A8385MvX0XhtNTTbhPt7GLb/npeKqvhj2U1vHqgnm6HxPg4PnJJPquXFXFZ0dSz0hNLZDBi\nCYSZwIFeyxXA0oHKuHunmTUA2eH6jX22nRnOO/BLM3PgB+5+/+CrL3Lu5Wem8NgXlnDj9zdwy8Ob\nWPflq04a/6m723njSNPxANi0t5bWji4iccalBZnc8b55LCzI4ndvVvPctoP8ZNtB3nleBquXFvGn\ni2eSkZwwiq2TySyWQOjvz5a+V6IHKnO6ba9290Nmlge8aGZvuPvvT/lyszXAGoCioqIYqity9s2f\nnsFDtxSz+sESvvDIZr75yYVs2VfLH8uO8nJZDUfD00Hz8tL59BWFXD0vh6VzpzGl187+Awumc9d1\n72T9q4d4YuM+/vGnO/g/z7/BikUzWL10FhfPzBzo60XOilgCoQIo7LVcABwaoEyFmcUDmUDt6bZ1\n957XKjN7juBU0imBEB453A9BL6MY6ityThTPnsa/rlrMl5/Ywge+9TsA8jKSeM87crl6Xg5Xz8vh\nvMzk035GWlI8q5YUsfKKQrZXNPBkyT6e23aQpzcdYGFBJquXzeKGS4d2D4XIYJ2x22m4g38TuAY4\nCGwGbnL3Hb3K3AFc4u5fMrOVwMfd/VNmdhHwFMHOfgbwK2A+kAzEuXuTmaUBLwL3uPsvTlcXdTuV\nsejFnZVU1B3jXfNymJeXPuxrAQ2tHTy3tYInS/bzVlUzGcnxfOKyAlYvLWL+9IwRqrVMFiM+dIWZ\nXQ/8C0G304fd/etmdg9Q6u7rzSwZeBxYTHBksLLXReh/AL4AdAJfdffnzWwu8Fz48fHAU+7+9TPV\nQ4Egk4m7s7m8jidL9vH8a0do7+rmyrnZ3HLVLD5w4fRRvzdjounqdto7uyfc0ZjGMhKZYI42R3mm\n9ABPbtzPwfpW8jOTWb20iJVLikZtMEF3Jxo+ZS85YXzvRBuOdfDZH27icH0rT69Zxvm56aNdpRGj\nQBCZoLq6nV/tquSxDfv4Y1kNiZE4PnxpPp8Nn+UwlNNV7s7B+la27a/ntYMN1LW009bZTWt7F20d\nXbR2dAXznV20tYfLHV20dQRhEIkzPnjhdFYvK+Lq83PG3QCAtS3t3PxQCW9VNpOeHE9CxHhmzZWD\nGgRxLFMgiEwCZVXNPLFxH+u2VNAc7eSSmZl89spZ3LBwxmn/Ym+OdrK9op5t++t55UDwWtMcBYJ7\nI6alJpKSGCE5IUJKQlz4GiE5MXhNSYiQnBB3fF1NUzvPbaug7lgHs7JTuWlJETdefuozJsaimuYo\nn3mwhL01Lfzg5suZkZXCyvs3khQfxzNrrqQo+/T3mIwHCgSRSaTnedCPbthHWVUzU1MT+PQVRaxe\nWsTMrBTKqpvZtr/u+M7/zcomusN/9nNz0lhUmMXioiwWFU7lnfkZJAzh2kRbRxcv7DjCkxv3s6k8\neArd8ovPY/XSIpbMmTYmb7qrbGzjpgc2crC+lYduuYKrw6FIdh1uZNUDG0lLjGftmmVnvPFwrFMg\niExC7s6Gt4/y6IZyXtxZCUBqYjzN4QiyU5LjWVQ0lcXHAyCLrNTE03zi0LxZ2cRTJfv58dYKmto6\nmZeXzk1LivjEZQVkpo6Nm+4O1bdy0wMbqW6K8vDnrmDp3OyT3n/9YAOrHywhIzmeZ26/kplZKaNU\n0+FTIIhMcgfrW3lm037qjnWwqDCLRUVZzMlOO6fn91vbu/jP7Yd4smQ/rx6oJyk+jhsWzmD10qIh\nX+8YCQdqj3HTgxupb+ngkS8s4fJZU/st91pFAzc9uJGpqYk8c/sy8jPHZygoEERkTHn9YANPbdrP\nT7cdpKW9ixmZyczNTWd2Tiqzs9OCKSeNommpZ/VRpeU1Ldz0wEaao508futSFhZmnbb8KwfqufnB\nEnIykli7ZhnTp5z+RsOxSIEgImNSc7STn75ykE17aymvaWFvTQuNbSceihRnMHNqykkhMadXaAzn\nCKesqpnVD26kvbObJ25bespT/wayZV8dn32ohOmZyaxds4y8jPEVCgoEERk36lra2Xu0hfKacDp6\njPKjQVg09QqL/Mxkrr8kn49cmj/oU067jzSx+sESwHnytmVccN7g7vjeXF7LLQ9vYkZWCmvXLBu1\nez+GQoEgIuOeu1Pb0k750WOUVTXx4s5Kfv9mDe1d3RRMTeHDl+Zzw6UzuGjGlNOGw45DDdz80Cbi\n44ynvriMeXlDu+ls456jfO6Hm5g1LY2n1yw7aYTbsUyBICITUkNrBy/urORn2w/xx7dq6Ox2Zmen\n8pFLZ/CRhflcMD3jpHDYXlHPzQ9tIi0xwlNfXDbsm81eLqvh849sZm5uOk/dtpSpwwyF7m6n7lg7\n1c1Rqhqjx58vXtUYPme8qY3qpigJkTh+8dV3D+k7FAgiMuHVtbTzwo4j/Gz7YV5+u4ZuD4Yb//Al\n+dywMJ+G1k4+9/AmMlMTePqLI3c/wR/equbWR0uZn5fOU7ctG7ArbbSzi8qGKIcaWjlU38rhhrbj\nr9VNUaqa2qhpbqer+9R9cFpi5PizxfMykpmRlcw/fLjvgypjo0AQkUmlpjnK868f4efbD1Gytxb3\nYEiNwqkpPPXFZcwY4fsIfrO7itsf28I78zO4/d3nc7ihlUP1PTv8Vg6FO/2+pqYmkJ+ZQt6UJPLC\nHX5uehJ5U5KPz+dmJJGWFNPj7mOiQBCRSauqsY3/eu0wrx1s5G+XX3DWuor+alclX3piCx1dwT40\nNTFCfmYyM7JSmJGZQn7WifkZWcnkZ6aMykiqCgQRkXOgou4Yja2dzMxKYUpK/JgcomMwgTByxyUi\nIpNMwdRU6P9G53FJT9gQERFAgSAiIiEFgoiIAAoEEREJKRBERARQIIiISEiBICIigAJBRERCCgQR\nEQEUCCIiElIgiIgIoEAQEZGQAkFERAAFgoiIhBQIIiICKBBERCSkQBAREUCBICIioZgCwcyWm9lu\nMyszs7v6eT/JzJ4J3y8xs9m93rs7XL/bzK7ts13EzLaZ2c+G2xARERmeMwaCmUWA7wLXAQuAVWa2\noE+xW4E6d58HfBu4N9x2AbASuAhYDtwXfl6PrwC7htsIEREZvliOEJYAZe6+x93bgbXAij5lVgCP\nhvPrgGvMzML1a9096u57gbLw8zCzAuDDwIPDb4aIiAxXLIEwEzjQa7kiXNdvGXfvBBqA7DNs+y/A\n3wLdg661iIiMuFgCwfpZ5zGW6Xe9mX0EqHL3LWf8crM1ZlZqZqXV1dVnrq2IiAxJLIFQART2Wi4A\nDg1UxszigUyg9jTbXg181MzKCU5Bvd/Mnujvy939fncvdvfi3NzcGKorIiJDEUsgbAbmm9kcM0sk\nuEi8vk+Z9cAt4fyNwK/d3cP1K8NeSHOA+cAmd7/b3QvcfXb4eb9298+MQHtERGSI4s9UwN07zexO\n4AUgAjzs7jvM7B6g1N3XAw8Bj5tZGcGRwcpw2x1m9iywE+gE7nD3rrPUFhERGQYL/pAfH4qLi720\ntHS0qyEiMm6Y2RZ3L46lrO5UFhERQIEgIiIhBYKIiAAKBBERCSkQREQEUCCIiEhIgSAiIoACQURE\nQgoEEREBFAgiIhJSIIiICKBAEBGRkAJBREQABYKIiIQUCCIiAigQREQkpEAQERFAgSAiIiEFgoiI\nAAoEEREJKRBERARQIIiISEiBICIigAJBRERCCgQREQEUCCIiElIgiIgIoEAQEZGQAkFERAAFgoiI\nhBQIIiICKBBERCSkQBARESDGQDCz5Wa228zKzOyuft5PMrNnwvdLzGx2r/fuDtfvNrNrw3XJZrbJ\nzF41sx1m9r9GqkEiIjI0ZwwEM4sA3wWuAxYAq8xsQZ9itwJ17j4P+DZwb7jtAmAlcBGwHLgv/Lwo\n8H53XwgsApab2bKRaZKIiAxFLEcIS4Ayd9/j7u3AWmBFnzIrgEfD+XXANWZm4fq17h51971AGbDE\nA81h+YRw8mG2RUREhiGWQJgJHOi1XBGu67eMu3cCDUD26bY1s4iZvQJUAS+6e8lQGiAiIiMjlkCw\nftb1/Wt+oDIDbuvuXe6+CCgAlpjZxf1+udkaMys1s9Lq6uoYqisiIkMRSyBUAIW9lguAQwOVMbN4\nIBOojWVbd68HfktwjeEU7n6/uxe7e3Fubm4M1RURkaGIJRA2A/PNbI6ZJRJcJF7fp8x64JZw/kbg\n1+7u4fqVYS+kOcB8YJOZ5ZpZFoCZpQAfAN4YfnNERGSo4s9UwN07zexO4AUgAjzs7jvM7B6g1N3X\nAw8Bj5tZGcGRwcpw2x1m9iywE+gE7nD3LjPLBx4NexzFAc+6+8/ORgNFRCQ2FvwhPz4UFxd7aWnp\naFdDRGTcMLMt7l4cS1ndqSwiIoACQUREQgoEEREBFAgiIhJSIIiICKBAEBGRkAJBREQABYKIiIQU\nCCIiAigQREQkpEAQERFAgSAiIiEFgoiIAAoEEREJKRBERARQIIiISEiBICIigAJBRERCCgQREQEU\nCCIiElIgiIgIoEAQEZGQAkFERAAFgoiIhBQIIiICKBBERCSkQBAREUCBICIiIQWCiIgACgQREQkp\nEEREBFAgiIhISIEgIiJAjIFgZsvNbLeZlZnZXf28n2Rmz4Tvl5jZ7F7v3R2u321m14brCs3sN2a2\ny8x2mNlXRqpBIiIyNGcMBDOLAN8FrgMWAKvMbEGfYrcCde4+D/g2cG+47QJgJXARsBy4L/y8TuCv\n3f1CYBlwRz+fKSIi51AsRwhLgDJ33+Pu7cBaYEWfMiuAR8P5dcA1Zmbh+rXuHnX3vUAZsMTdD7v7\nVgB3bwJ2ATOH3xwRERmqWAJhJnCg13IFp+68j5dx906gAciOZdvw9NJioKS/LzezNWZWamal1dXV\nMVRXRESGIpZAsH7WeYxlTrutmaUDPwa+6u6N/X25u9/v7sXuXpybmxtDdUVEZChiCYQKoLDXcgFw\naKAyZhYPZAK1p9vWzBIIwuBJd//JUCovIiIjJ5ZA2AzMN7M5ZpZIcJF4fZ8y64FbwvkbgV+7u4fr\nV4a9kOYA84FN4fWFh4Bd7v6tkWiIiIgMT/yZCrh7p5ndCbwARICH3X2Hmd0DlLr7eoKd++NmVkZw\nZLAy3HaHmT0L7CToWXSHu3eZ2buAm4HXzOyV8Kv+3t3/a6QbKCIisbHgD/nxobi42EtLS0e7GiIi\n44aZbXH34ljK6k5lEREBFAgiIhJSIIiICKBAEBGRkAJBREQABYKIiIQUCCIiAigQREQkpEAQERFA\ngSAiIqHJEQhdHaNdAxGRMe+Mg9tNCP98PlgEMvIh47xerz3z4XJ6HkQSRru2IiKjYuIHgjtc+efQ\ndBiajgSvVbuguRK8q09hg7TcXuGQBHGRcIoPp0gQLr2Xe95PyoCpc2DaHJg2F5IzR6XJIiJDMfED\nwQze8zenru/ugpaak4Oi92tLVXCqqbsLujuDybtOXu7utexd0NV+8nekZgfBMG1uGBRzT0yp04K6\njSWNh6FiMxzaFhw1XfxxSMsZ7VqJyDky8QNhIHERyJgeTCMl2gx15VC7J5jq9gav+16G7c9y0pNH\nk6YERxKZhcHOd0p+r9NX4XLSlLMXGh2tcPjVIAAqSoOpsSJ4zyJBwL1wN8y/FhauhHdcC/FJZ6cu\nIjImTN5AOBuS0uG8i4Opr442qN8HtXtPBEbtHjhaBuV/gLaGU7dJSD05IHqudSRlQGIaJKaHr73m\nE1KD+Uivn9Y9+K6K0jAANkPl68GRDUBWERQthYI7YWYxnHdJUK9Xn4bXfgS7fw4pU+HiT8DCVTDz\n8rF3dCMiw6YH5IwV7S0nn7JqPBQuHzp5uSsa2+dFkk4ERXsTtNYF6xPSYOZlUHBFOBUH10sG0tUJ\ne34Lrz4Fb/wcOtsge35w1HDppyGrcOBtRWTUDeYBOQqE8cQd2uqDU1PtLeHUDB3HTsz3Xt8zH0kI\n/qovuAJy3xmcLhuKtgbY+VN45WnY/zJgMOdPgqOGCz8aHCGNBd3d0FINDRXQfCQIxbTcYEqdNvT2\ni4xDCgQ5+2r3BtdFXn06uFYSnxxcOM+cCVNmQmZB+DoTphQErwkpI/Pd7ceg8SA0HAh2+sennuWD\npzmSsuBif3pecMG8JyiOz4frU6YFp8lSshQgk0FnFHauh+4OuORTJ59yHecUCHLuuMOBkuAfU115\ncGG64SAcqzm1bMq0kwMiNTvomdXZHuzAO6Phcs989NT3WmpO/WyLC66vZBb0mgqD1/TpwRFUS3Ww\nbUs1NFedvNxSA9F+ruH0SM48ERCpPUHRd3lqUC45K3zNhITkEf1PPWjdYbdqBdrAmiqh9OFgaqkK\n1s1YDB/9t+Ba2gSgQJDR19EW/BXfeDAIiJ6g6L3c1gBxCUHvpUhi8BqfFFz/iE8MX/usS5ka7uwL\nT+z8p8wY/g2FndGTA6K1Dlpr4VjtifnWunA5nO+vI0Bv8cknwqFvWKRkQdYsyJkP2fOCo5PhXKjv\nbIfqN4KeYz1T5etBKOS9E6ZfDNMvgrwFwXx67tC/ayI4uBVKvg+v/yQ4Kpj/IVj6peA3ff5vg9/5\n6r+A9/zdyB3ZjhIFgowP7uO7t1JXZ7ADaa2F1vpgvq0+nBrC93rN913f+8bI5MwgGLLnQ07P6/zg\nnpW+O6SOVqjcAYdfObHzr9p14j6YxIzgr9v8hcHRQdXOoHxz5YnPSMsLAqL3lHPB6B/VnE1dHcE1\nsJIfQMWm4NrSotWw9HbIPv9EuWO18OI/wrYngv/+N3wH5rx79Oo9TAoEkbGuuyu45lFTFnTxPfoW\n1LwVzDce7FXQgqOhnHnBaaqqnVC9+0SYpEwNdvzHp0XBtZy4foYpa6kJgqFnqtoRBElnW/hVkSCU\nps4Kh3WZcfL9MVNmBHXo77PPxD34nrZGiDYFPeAyzjs3fxC01MCWR2DzQ0GvvWlzYcntsOgmSJ4y\n8HZ7fgf/+ZXgGtnim+FD/zv47z3OKBBExrP2Fjj6dhgSvcLiWC3kXXhyAGQWDG+n2t0V3KNS+TpU\n7gwCp+FAcNd6SzUn3UwJwSm+4/fFhKGRmh30aos2hVO4029rPDEfbTxx30uP9OnB+fre0+m6QA+q\nXd1Q+Rpsuh+2/yi4DjX3fbDsyzDvg7GHWkcr/PYb8PK/Be28/p9hwYpxdWSrQBCR4evqCE4zNR4O\n/rJuPBys5fU2AAAF+UlEQVTeJ3M4vC/mcLCuoyUIiuQpwd31SRnBa3LPfMaJ9T1ljtUGp7wObQuO\neHqCZ8rMIBjyF4Uhsaj/4VOiTSd6lPXX26zxUHBtICE1uGdmye3BtZShOvwqrP/z4PWC6+H6bwYd\nI8YBBYKInDud7cEF/6GKNsOR7UE49ExHy068n1kE+ZcGRxg9O/y+F/QtEpzS6t3TbOocWPDRkTvN\n09UJJd+DX389GMzyg1+Dy78wtFNo55ACQUTGt7aG4K/xnoA48hrEp/TpWtyre3HGeeeue23tXvjZ\nX8Ke30DhMrjkxuACdVJ6r2Fkes0npQe96Po7zdTdHRxhRZuCYIw2BSML9F22CLzrq0OqrgJBRORs\ncodX18ILfx/0MjuTuPgTARGfHNwbE20Orr30vU7Tn/Tp8N/eHFJVBxMIE+d2PBGRc8UMFq0Kjg5a\n604MFXN8WJnmXsPHNJ883Exna3Bto+f6SmJ6r2st/SwnZZyzkYYVCCIiQxVJCHtGjVDvqFE2tq+G\niIjIOaNAEBERQIEgIiKhmALBzJab2W4zKzOzu/p5P8nMngnfLzGz2b3euztcv9vMru21/mEzqzKz\n10eiISIiMjxnDAQziwDfBa4DFgCrzGxBn2K3AnXuPg/4NnBvuO0CYCVwEbAcuC/8PIBHwnUiIjIG\nxHKEsAQoc/c97t4OrAVW9CmzAng0nF8HXGNmFq5f6+5Rd98LlIWfh7v/HoihA6+IiJwLsQTCTOBA\nr+WKcF2/Zdy9E2gAsmPc9rTMbI2ZlZpZaXV19WA2FRGRQYglEPob1q/vrXUDlYll29Ny9/vdvdjd\ni3NzJ/lDPUREzqJYbkyrAAp7LRcAhwYoU2Fm8UAmwemgWLaN2ZYtW2rMbN8QN88B+nmu46QwmdsO\nk7v9avvk1dP+WbFuEEsgbAbmm9kc4CDBReKb+pRZD9wCbABuBH7t7m5m64GnzOxbwAxgPrAp1sr1\n5e5DPkQws9JYx/OYaCZz22Fyt19tn5xth6G1/4ynjMJrAncCLwC7gGfdfYeZ3WNmHw2LPQRkm1kZ\n8FfAXeG2O4BngZ3AL4A73INHPZnZ0wQBcoGZVZjZrYOpuIiIjKxxNdrpcEzmvxYmc9thcrdfbZ+c\nbYezdIQwgdw/2hUYRZO57TC526+2T16Dbv+kOUIQEZHTm0xHCCIichoTPhDONA7TRGdm5Wb2mpm9\nYmYT+nFz/Y2PZWbTzOxFM3srfB2hB+yOPQO0/2tmdjD8/V8xs+tHs45ni5kVmtlvzGyXme0ws6+E\n6yf873+atg/6t5/Qp4zCcZPeBD5IcE/EZmCVu+8c1YqdQ2ZWDhS7+4Tvj21m7waagcfc/eJw3f8F\nat39G+EfBFPd/e9Gs55nywDt/xrQ7O7fHM26nW1mlg/ku/tWM8sAtgB/CnyOCf77n6btn2KQv/1E\nP0KIZRwmmSAGGB+r9zhbjxL8Q5mQJvP4YO5+2N23hvNNBF3kZzIJfv/TtH3QJnogDHsspQnAgV+a\n2RYzWzPalRkF0939MAT/cJgozzocnDvNbHt4SmnCnTLpKxx+fzFQwiT7/fu0HQb520/0QBj2WEoT\nwNXufhnB8OV3hKcVZPL4HnA+sAg4DPy/0a3O2WVm6cCPga+6e+No1+dc6qftg/7tJ3ogjOhYSuOR\nux8KX6uA5wiHH59EKsNzrD3nWqtGuT7nlLtXunuXu3cDDzCBf38zSyDYIT7p7j8JV0+K37+/tg/l\nt5/ogXB8HCYzSyQYh2n9KNfpnDGztPAiE2aWBnwImGxPqOsZZ4vw9aejWJdzrmdnGPoYE/T3D5+/\n8hCwy92/1eutCf/7D9T2ofz2E7qXEUDY1epfgAjwsLt/fZSrdM6Y2VyCowIIBjJ8aiK3Pxwf670E\nozxWAv8T+A+C8bSKgP3AJ919Ql54HaD97yU4ZeBAOXB7zzn1icTM3gX8AXgN6A5X/z3BufQJ/fuf\npu2rGORvP+EDQUREYjPRTxmJiEiMFAgiIgIoEEREJKRAEBERQIEgIiIhBYKIiAAKBBERCSkQREQE\ngP8PZi/Yr/g5ipUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a18545be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "list_d_loss, list_g_loss = [], []\n",
    "for d_loss, g_loss in losses:\n",
    "    list_d_loss.append(d_loss)\n",
    "    list_g_loss.append(g_loss)\n",
    "\n",
    "#plt.plot(list_d_loss)\n",
    "plt.plot(list_g_loss)\n",
    "plt.plot(list_d_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/lstm_ae_wa/lstm_ae_wa.ckpt-2520000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a184a5978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "latent_space = sess.run(encoder_output, feed_dict={x_input: X})\n",
    "reducer = TruncatedSVD()\n",
    "latent_space_2d = reducer.fit_transform(latent_space)\n",
    "x_plot, y_plot = zip(*latent_space_2d)\n",
    "plt.scatter(x_plot, y_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__)  # for Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jinpark/anaconda/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
